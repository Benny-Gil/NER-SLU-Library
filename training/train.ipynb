{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning a spaCy NER Model with arXiv Summaries\n",
    "I'll create a notebook that fine-tunes a spaCy NER model using the scientific summaries you've extracted. Since the summaries don't have pre-labeled entities, we'll use a two-step approach:\n",
    "1. Use an existing spaCy model to pre-annotate entities\n",
    "2. Fine-tune the model on these annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Loaded 3000 summaries\n",
      "\n",
      "Example summaries:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>We present a general, consistency-based framew...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In this paper we present a transformation of f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>We consider the integration of existing cone-s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>We introduce Ak, an extension of the action de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Evolutionary artificial neural networks (EANNs...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             summary\n",
       "0  We present a general, consistency-based framew...\n",
       "1  In this paper we present a transformation of f...\n",
       "2  We consider the integration of existing cone-s...\n",
       "3  We introduce Ak, an extension of the action de...\n",
       "4  Evolutionary artificial neural networks (EANNs..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import random\n",
    "from spacy.tokens import DocBin\n",
    "from spacy.util import minibatch, compounding\n",
    "from pathlib import Path\n",
    "import csv\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "# 1. Load the data\n",
    "print(\"Loading dataset...\")\n",
    "summaries_df = pd.read_csv('data/arXiv_summaries_3000.csv')\n",
    "# Display a few examples\n",
    "print(f\"Loaded {len(summaries_df)} summaries\")\n",
    "print(\"\\nExample summaries:\")\n",
    "summaries_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pre-annotating entities using existing model...\n",
      "Using existing en_core_web_lg model\n"
     ]
    }
   ],
   "source": [
    "# 2. Pre-annotate data using an existing model\n",
    "print(\"\\nPre-annotating entities using existing model...\")\n",
    "\n",
    "# load large pre-existing model\n",
    "try:\n",
    "    nlp = spacy.load(\"en_core_web_lg\")\n",
    "    print(\"Using existing en_core_web_lg model\")\n",
    "except OSError:\n",
    "    print(\"Model not found. Installing en_core_web_lg...\")\n",
    "    subprocess.check_call([\n",
    "        spacy.cli.download(\"en_core_web_lg\")\n",
    "    ])\n",
    "    nlp = spacy.load(\"en_core_web_lg\")\n",
    "    print(\"Successfully installed and loaded en_core_web_lg model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 100/3000 summaries\n",
      "Processed 200/3000 summaries\n",
      "Processed 300/3000 summaries\n",
      "Processed 400/3000 summaries\n",
      "Processed 500/3000 summaries\n",
      "Processed 600/3000 summaries\n",
      "Processed 700/3000 summaries\n",
      "Processed 800/3000 summaries\n",
      "Processed 900/3000 summaries\n",
      "Processed 1000/3000 summaries\n",
      "Processed 1100/3000 summaries\n",
      "Processed 1200/3000 summaries\n",
      "Processed 1300/3000 summaries\n",
      "Processed 1400/3000 summaries\n",
      "Processed 1500/3000 summaries\n",
      "Processed 1600/3000 summaries\n",
      "Processed 1700/3000 summaries\n",
      "Processed 1800/3000 summaries\n",
      "Processed 1900/3000 summaries\n",
      "Processed 2000/3000 summaries\n",
      "Processed 2100/3000 summaries\n",
      "Processed 2200/3000 summaries\n",
      "Processed 2300/3000 summaries\n",
      "Processed 2400/3000 summaries\n",
      "Processed 2500/3000 summaries\n",
      "Processed 2600/3000 summaries\n",
      "Processed 2700/3000 summaries\n",
      "Processed 2800/3000 summaries\n",
      "Processed 2900/3000 summaries\n",
      "Processed 3000/3000 summaries\n",
      "\n",
      "Created 3000 training examples\n"
     ]
    }
   ],
   "source": [
    "# Create training data\n",
    "TRAIN_DATA = []\n",
    "\n",
    "# Process in batches to improve speed\n",
    "batch_size = 100\n",
    "for i in range(0, len(summaries_df), batch_size):\n",
    "    batch = summaries_df['summary'][i:i+batch_size]\n",
    "    for text in batch:\n",
    "        doc = nlp(text)\n",
    "        entities = []\n",
    "        for ent in doc.ents:\n",
    "            entities.append((ent.start_char, ent.end_char, ent.label_))\n",
    "        TRAIN_DATA.append((text, {\"entities\": entities}))\n",
    "    print(f\"Processed {min(i+batch_size, len(summaries_df))}/{len(summaries_df)} summaries\")\n",
    "\n",
    "print(f\"\\nCreated {len(TRAIN_DATA)} training examples\")3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 2400 examples\n",
      "Evaluation set: 600 examples\n"
     ]
    }
   ],
   "source": [
    "# 3. Split into training and evaluation sets\n",
    "random.shuffle(TRAIN_DATA)\n",
    "split = int(len(TRAIN_DATA) * 0.8)  # 80% train, 20% eval\n",
    "train_data = TRAIN_DATA[:split]\n",
    "eval_data = TRAIN_DATA[split:]\n",
    "\n",
    "print(f\"Training set: {len(train_data)} examples\")\n",
    "print(f\"Evaluation set: {len(eval_data)} examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 2400 examples to ./corpus/train.spacy\n",
      "Saved 600 examples to ./corpus/eval.spacy\n"
     ]
    }
   ],
   "source": [
    "# 4. Convert to spaCy's binary format\n",
    "def convert_to_spacy(data, output_path):\n",
    "    nlp = spacy.blank(\"en\")  # Create blank Language class\n",
    "    db = DocBin()  # Create a DocBin object\n",
    "    \n",
    "    for text, annot in data:\n",
    "        doc = nlp.make_doc(text)  # Create Doc object\n",
    "        ents = []\n",
    "        for start, end, label in annot[\"entities\"]:\n",
    "            span = doc.char_span(start, end, label=label)\n",
    "            if span is not None:  # Some spans might be invalid\n",
    "                ents.append(span)\n",
    "        doc.ents = ents  # Add entities to Doc\n",
    "        db.add(doc)\n",
    "    \n",
    "    db.to_disk(output_path)  # Save to disk\n",
    "    print(f\"Saved {len(data)} examples to {output_path}\")\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "Path(\"./corpus\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Convert and save data\n",
    "convert_to_spacy(train_data, \"./corpus/train.spacy\")\n",
    "convert_to_spacy(eval_data, \"./corpus/eval.spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Create config file for training\n",
    "config = \"\"\"\n",
    "[paths]\n",
    "train = \"./corpus/train.spacy\"\n",
    "dev = \"./corpus/eval.spacy\"\n",
    "vectors = null\n",
    "[system]\n",
    "gpu_allocator = \"mps\"\n",
    "seed = 0\n",
    "[nlp]\n",
    "lang = \"en\"\n",
    "pipeline = [\"tok2vec\", \"ner\"]\n",
    "batch_size = 1000\n",
    "[components]\n",
    "[components.tok2vec]\n",
    "factory = \"tok2vec\"\n",
    "[components.tok2vec.model]\n",
    "@architectures = \"spacy.Tok2Vec.v2\"\n",
    "[components.tok2vec.model.embed]\n",
    "@architectures = \"spacy.MultiHashEmbed.v2\"\n",
    "width = ${components.tok2vec.model.encode.width}\n",
    "attrs = [\"LOWER\", \"PREFIX\", \"SUFFIX\", \"SHAPE\"]\n",
    "rows = [5000, 1000, 1000, 2500]\n",
    "include_static_vectors = false\n",
    "[components.tok2vec.model.encode]\n",
    "@architectures = \"spacy.MaxoutWindowEncoder.v2\"\n",
    "width = 96\n",
    "depth = 4\n",
    "window_size = 1\n",
    "maxout_pieces = 3\n",
    "[components.ner]\n",
    "factory = \"ner\"\n",
    "incorrect_spans_key = null\n",
    "moves = null\n",
    "scorer = {\"@scorers\":\"spacy.ner_scorer.v1\"}\n",
    "update_with_oracle_cut_size = 100\n",
    "[components.ner.model]\n",
    "@architectures = \"spacy.TransitionBasedParser.v2\"\n",
    "state_type = \"ner\"\n",
    "extra_state_tokens = false\n",
    "hidden_width = 64\n",
    "maxout_pieces = 2\n",
    "use_upper = true\n",
    "nO = null\n",
    "[components.ner.model.tok2vec]\n",
    "@architectures = \"spacy.Tok2VecListener.v1\"\n",
    "width = ${components.tok2vec.model.encode.width}\n",
    "upstream = \"*\"\n",
    "[training]\n",
    "dev_corpus = \"corpora.dev\"\n",
    "train_corpus = \"corpora.train\"\n",
    "seed = ${system.seed}\n",
    "gpu_allocator = ${system.gpu_allocator}\n",
    "dropout = 0.1\n",
    "accumulate_gradient = 1\n",
    "patience = 1600\n",
    "max_epochs = 0\n",
    "max_steps = 20000\n",
    "eval_frequency = 200\n",
    "frozen_components = []\n",
    "annotating_components = []\n",
    "before_to_disk = null\n",
    "[training.batcher]\n",
    "@batchers = \"spacy.batch_by_words.v1\"\n",
    "discard_oversize = false\n",
    "tolerance = 0.2\n",
    "get_length = null\n",
    "[training.batcher.size]\n",
    "@schedules = \"compounding.v1\"\n",
    "start = 100\n",
    "stop = 1000\n",
    "compound = 1.001\n",
    "t = 0.0\n",
    "[training.logger]\n",
    "@loggers = \"spacy.ConsoleLogger.v1\"\n",
    "progress_bar = true\n",
    "[training.optimizer]\n",
    "@optimizers = \"Adam.v1\"\n",
    "beta1 = 0.9\n",
    "beta2 = 0.999\n",
    "L2_is_weight_decay = true\n",
    "L2 = 0.01\n",
    "grad_clip = 1.0\n",
    "use_averages = false\n",
    "eps = 0.00000001\n",
    "learn_rate = 0.001\n",
    "[training.score_weights]\n",
    "ents_f = 1.0\n",
    "ents_p = 0.0\n",
    "ents_r = 0.0\n",
    "ents_per_type = null\n",
    "[pretraining]\n",
    "[initialize]\n",
    "vectors = null\n",
    "vocab_data = null\n",
    "lookups = null\n",
    "before_init = null\n",
    "after_init = null\n",
    "[initialize.components]\n",
    "[initialize.tokenizer]\n",
    "\"\"\"\n",
    "# Write config file\n",
    "with open(\"./config.cfg\", \"w\") as f:\n",
    "    f.write(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "To train the model, run the following commands in your terminal:\n",
      "\n",
      "cd /Users/benny/Projects/NER-SLU-Library/training\n",
      "python -m spacy train config.cfg --output ./output\n"
     ]
    }
   ],
   "source": [
    "# 6. Train the model (showing commands - run in terminal)\n",
    "print(\"\\nTo train the model, run the following commands in your terminal:\\n\")\n",
    "print(\"cd /Users/benny/Projects/NER-SLU-Library/training\")\n",
    "print(\"python -m spacy train config.cfg --output ./output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Detected entities:\n",
      "MANILA - ORG\n",
      "Philippines — The - ORG\n",
      "President Rodrigo Duterte - ORG\n",
      "the Philippine National Police - ORG\n",
      "Sen. Antonio Trillanes IV - ORG\n",
      "Saturday - GPE\n",
      "Trillanes - ORG\n",
      "PNP Chief Gen. Rommel Marbil - ORG\n",
      "Gen. Nicolas Torre - ORG\n",
      "PNP Criminal Investigation - ORG\n",
      "PNP-CIDG - ORG\n",
      "the International Criminal Court - ORG\n",
      "PNP - ORG\n",
      "Filipinos - ORG\n",
      "Trillanes - ORG\n"
     ]
    }
   ],
   "source": [
    "# # 7. Code for loading and testing the trained model\n",
    "# Load the trained model\n",
    "trained_nlp = spacy.load(\"./output/model-best\")\n",
    "\n",
    "# testing the trained model\n",
    "sample_text = \"\"\"MANILA, Philippines — The methodical handling of the arrest of former President Rodrigo Duterte could redeem the “good image” of the Philippine National Police, said former Sen. Antonio Trillanes IV on Saturday.\n",
    "In a radio interview, Trillanes praised PNP Chief Gen. Rommel Marbil and Maj. Gen. Nicolas Torre, head of the PNP Criminal Investigation and Detection Group (PNP-CIDG), for showing professionalism even when Duterte’s relatives and lawyers tried to prevent them from implementing the International Criminal Court’s (ICC) arrest order.\n",
    "“So far, we see (the PNP) as very professional compared to the time of Duterte when (police officers) themselves were involved in killing ordinary Filipinos whom they were supposed to protect,” Trillanes said in the “Usapang Senado” program on dwIZ.\"\"\"\n",
    "doc = trained_nlp(sample_text)\n",
    "\n",
    "print(\"\\nDetected entities:\")\n",
    "for ent in doc.ents:\n",
    "    print(f\"{ent.text} - {ent.label_}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    MANILA\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Philippines — The\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " methodical handling of the arrest of former \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    President Rodrigo Duterte\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " could redeem the “good image” of \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    the Philippine National Police\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ", said former \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Sen. Antonio Trillanes IV\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " on \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Saturday\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ".<br><br>In a radio interview, \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Trillanes\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " praised \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    PNP Chief Gen. Rommel Marbil\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " and Maj. \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Gen. Nicolas Torre\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ", head of the \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    PNP Criminal Investigation\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " and Detection Group (\n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    PNP-CIDG\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       "), for showing professionalism even when Duterte’s relatives and lawyers tried to prevent them from implementing \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    the International Criminal Court\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       "’s (ICC) arrest order.<br><br>“So far, we see (the \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    PNP\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ") as very professional compared to the time of Duterte when (police officers) themselves were involved in killing ordinary \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Filipinos\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " whom they were supposed to protect,” \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Trillanes\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " said in the “Usapang Senado” program on dwIZ.</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 8. Visualization of the entities\n",
    "from spacy import displacy\n",
    "displacy.render(doc, style=\"ent\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
